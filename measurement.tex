\documentclass[11pt,twoside]{article}
\usepackage[toc,page,header]{appendix}
\usepackage{pdfpages}
\usepackage{csquotes}
\usepackage{changepage}
\usepackage{fontspec}
\usepackage{mathtools}
\usepackage{amsfonts}
\defaultfontfeatures{Scale=MatchLowercase}
\setmainfont[Mapping=tex-text]{Times New Roman}
\setsansfont[Mapping=tex-text]{Arial}
\setmonofont{Courier}

\usepackage{float}
\usepackage{turnstile}
\usepackage{bussproofs}

\usepackage{geometry}
\geometry{letterpaper}

\newtheorem{theorem}{Theorem}
%\newtheorem{cor}{Corollary}
%\newtheorem{lem}{Lemma}
%\theoremstyle{remark}
\newtheorem{remark}{Remark}

\newtheorem{objection}{Objection}
\newenvironment*{response}[1][]{\noindent
\textbf{Response to Objection #1.}
\begin{adjustwidth}{1em}{1em}
}
{\end{adjustwidth}
\vspace{1ex}
}


%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent

\usepackage{graphicx}
\usepackage[leftcaption]{sidecap}
\sidecaptionvpos{figure}{c}

%\usepackage{amssymb}

\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\usepackage[
bibstyle=numeric,
citestyle=authortitle,
natbib=true,
hyperref,bibencoding=utf8,backref=true,backend=biber]{biblatex}

\usepackage{hyperref}
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
    unicode=true,          % non-Latin characters in Acrobat’s bookmarks
    pdftoolbar=true,        % show Acrobat’s toolbar?
    pdfmenubar=true,        % show Acrobat’s menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={Mensuration without Representation},    % title
    pdfauthor={Author},     % author
    pdfsubject={Subject},   % subject of the document
    pdfcreator={Creator},   % creator of the document
    pdfproducer={Producer}, % producer of the document
    pdfkeywords={keyword1} {key2} {key3}, % list of keywords
    pdfnewwindow=true,      % links in new window
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=blue,          % color of internal links
    citecolor=blue,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}
\usepackage{draftwatermark}


\usepackage{fancyhdr}
\setlength{\headheight}{15.2pt}
\pagestyle{fancy}

\lhead[Measurement]{\thepage}
\chead[]{}
\rhead[\thepage]{Measurement}

\title{Mensuration without Representation \\
or: Answering Brandom's Question: \\
Pragmatism, Measurement, and the Human Sciences}
\author{G. A. Reynolds}
\date{\today}
\bibliography{%
../bib/abstracts.bib,%
../bib/causality.bib,%
../bib/em.bib,%
../bib/logic.bib,%
../bib/math.bib,%
../bib/mind.bib,%
../bib/philosophy.bib,%
../bib/pragmatism.bib,%
../bib/psychomet.bib%
../bib/psychometrics.bib,%
../bib/misc.bib,%
../bib/measurement.bib,%
../bib/psychology.bib,%
../bib/variables.bib,%
../bib/val.bib,%
../bib/validity.bib,%
}

\newcommand{\SR}{Survey Research}
\newcommand{\sr}{survey research}
\newcommand{\SRIV}{Survey Interview}
\newcommand{\sriv}{survey interview}
\newcommand{\SIV}{Survey Interviewing}
\newcommand{\FI}{Field Interviewer}
\newcommand{\Iver}{Interviewer}
\newcommand{\R}{Respondent}
\newcommand{\LPR}{Legal Permanent Resident}
\newcommand{\ART}{Assimilated Response Technique}
\newcommand{\GAM}{Grouped Answer Method}
\newcommand{\IOM}{Instrument of Measurement}

\includeonly{%
%% pilots,cards
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle
\nocite{*}

\begin{abstract}
  This paper is organized as follows.  It begins with an overview of
  the major themes of contemporary pragmatism, with particular focus
  on inferential semantics and linguistic expressivism.  Conceptual
  content is viewed as inferentially articulated, as opposed to
  representatial.  The inferential structure is instituted by
  proprieties of practice.  The representational dimension of language
  use is to be explained in terms of the social structure of the
  discursive practices that institute meaning.  The role of language
  is to express rather than represent; it allows us to say what we can
  otherwise only do.

  Then we move to an overview of the major theories of measurement on
  the contemporary scene, especially in the human (behavioral)
  sciences, with special focus on the role of measurement in \SR{}.

  Having examined the theories, we step back and address the more
  general issue of critera of adequacy for any theory of measurement.
  Any account of measurement must address the two fundamental aspects
  of measurement: mathematics on the one hand, and the relation of
  measurement concepts to the world, on the other.  In other words,
  measurement theory always involves at least two vocabularies: a
  vocabulary of mathematics, and an empirical vocabulary, and the task
  of the theory is to make them ``match''.

  Then we proceed to the critical part of the paper.  I show how the
  pragmatist perspective exposes problems in the popular accounts of
  measurement, with special focus on the survey research.

  Finally we move to the constructive part of the paper.  I show how
  an acceptable account of measurement can be constructed out of
  purely pragmatist materials.
\end{abstract}


\begin{remark}
Brandom's Question is (roughly): ``what features must be exhibited by
practices in order that those practices count as having conceptual
content?''  In the case of measurement, the question may be restated
as ``what features must be exhibited by our measurement practices so
that they be counted as genuinely having the character of
measurement?'' [TODO: refine this]

Alternatively, Price's Question: something like ``what is the science
of us that accounts for our conceptual activities?''

thus: ``The Pragmatic Question'', the question pragmatism asks that
integrates philosophy and science; what story can we tell about
ourselves that is at the same time a (the right) story about natural
science?  (See Talisse's intro)
\end{remark}

\begin{remark}
  This paper focuses on the conceptual and pragmatic foundations of
  measurement; it touches on related notions like validity,
  reliability, and error but does not examine them in detail, leaving
  that to other papers.
\end{remark}

\tableofcontents
\listoffigures

%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Introduction}

First Principle of Measurement: to measure is to compare.

Second Principle of Measurement:  to compare is to categorize.

\begin{remark}
  Measurement essentially involves two measurands.  You cannot measure
  an individuum without involving a second individuum.
\end{remark}

\begin{remark}
  These principles are not as simple as they look.  They involve a
  fundamental philosophical issue, namely the nature of representation
  and its relation to practice.
\end{remark}

Measurement talk involves two vocabularies, one mathematical and the
other empirical.  The fundamental task of quantitative measurement is
to map the former to the latter.  This boils down to mapping the
mathematical concept of ``unit'' to some empirical concept, like
meter, kilogram, or degree Kelvin.  But notice that such empirical
concepts are concepts, not observables.  The ``size'' of an empirical
unit is arbitrary; it is something we invent or stipulate, not
something we discover in nature.  We might discover extent in space,
but we do not discover inches or centimeters.  Hence there is no
question of verification or validation of empirical units.  There is
no point in trying to ``prove'' that, say, the concept of meter
corresponds to some fact in the world, that it truly is a meter long.
On the other hand, the concept must be connected to the world in some
way; we need to make a distinction between genuine empirical units
like ``meter'' and bogus units implicated by notions such as degree of
sinfulness or the ``weight'' of the soul.  The empirical vocabulary
must refer.  The critical question for psychological and social
measurement is whether it makes sense to talk of units of
e.g. attitude (approval, etc.).

Measurement schemes based on ratios try to get around this but they
don't really succeed; the concept of ratio depends on that of unit.
That said, it is true that ratios get us to a more abstract notion of
number, since (as the Greeks knew) you can compare ratios of different
kinds.  So while you cannot add e.g. lengths and areas, you can
compare ratios of lengths to ratios of areas.  Nonetheless, the
components of a ratio must be quantities involving an empirical unit.
Different ratios of the same kind (e.g. length) will implicitly
involve a unit.

The various ``theories'' of validity found in fields like
psychometrics are really about this referring relation between
empirical terms and the world.  

%%%%%%%%%%%%%%%%%%%%
\section{Paradigmatic Examples of Measurement}

\begin{remark}
Discussions of measurement are often highly abstract, and depending on
the discipline may introduce specialized vocabulary familiar only to
readers with experience in the discipline.  To make our text
intelligible to non-specialists we need specific, detailed, and to the
extent possible simple examples of actual measurement.
\end{remark}

\begin{itemize}
\item Primitive measurement: counting, height, weight
\item Time: undoubtedly the most important development in the history
  of scientific measurement is the measurement of time.  Yet papers on
  measurement rarely (in my experience, at least) discuss this topic.
\item Temperature
\item Hardness (Mohs scale)
\item Flavor (as opposed to e.g. sweetness)
\item Timbre, e.g. brass v. strings
\item Psychology
\begin{itemize}
\item Psychophysics - measurement of perception, e.g. loudness, sweetness, color perception, etc.
\item Personality measurement - anxiety, etc.; the \href{http://en.wikipedia.org/wiki/Big_Five_personality_traits}{Big Five Personality Traits}
\item Intelligence
\item Test theory?
\item Cognitive Psychology?
\end{itemize}
\item Sociology
\begin{itemize}
\item Unemployment rate
\item Religiosity
\item What are the best (simplest, most common, etc.) examples of sociological measures?
\end{itemize}
\item Anthropology
\begin{itemize}
\item Do anthropologists measure?  Insofar as they analyze structure,
  it is in principle possible to see what they do as mapping cultural
  constructs to mathematical structures; see below.
\end{itemize}
\item Economics
\item Linguistics?
\end{itemize}

%%%%%%%%%%%%%%%%%%%%
\section{Mathematics}
\subsection{An Unnatural History of Number}

\begin{abstract}
  Most accounts of measurement, at least in the behavioral sciences,
  involve some notion of assigning numbers, but usually do not look
  very closely at the concept of number.  Since the term ``number''
  covers a variety of distinct concepts (both historically and
  theoretically) we should start by getting clear about just what
  we're talking about.
\end{abstract}

It's hard to see how to talk about number without circularity, since
we do not have an antecedent notion of number that we can apply to all
the relevant historical concepts.  The history of concepts
recognizably involving something like ``number'' (in the West) is
complex so take what follows very schematically.  See
\href{http://ocw.mit.edu/courses/special-programs/sp-2h3-ancient-philosophy-and-mathematics-fall-2009/}{Ancient
  Philosophy and Mathematics} (MIT Open Courseware);
\cite{hoyrup_lengths_2002}; \cite{grattan-guinness_numbers_1996};
\href{http://aleph0.clarku.edu/~djoyce/java/elements/}{Euclid's Elements}. For
example,
\href{http://ocw.mit.edu/courses/special-programs/sp-2h3-ancient-philosophy-and-mathematics-fall-2009/assignments/MITSP\_2H3F09\_ses5.pdf}{The
  Greek Conception of Number}, gives examples showing that ``from the
Greeks through at least the middle ages `one' was not held to be a
number''.

\begin{enumerate}
\item Euclidean ``quantities'' - three distinct kinds of quantity
\begin{itemize}
\item Arithmetic Number (counting discrete quantities).  cf. \href{http://www.perseus.tufts.edu/hopper/text?doc=Perseus\%3Atext\%3A1999.04.0057\%3Aentry\%3Da)riqmo\%2Fs}{ἀριθμός} (\textit{arithmos}, number).  Euclid: ``A number is a multitude composed of units.''
\item Geometric Magnitude (measuring continuous quantities).  Length of a line, area of a square, volume of a solid.
\item Ratio.  Harmonic?  ``[T]he trio of Euclidean quantities,
  number–magnitude–ratio, surely bears an intentional cultural
  correlation with three subjects of the Aristotelian quadrivium,
  arithmetica–geometria–harmonia.'' \cite[367]{grattan-guinness_numbers_1996}
\end{itemize}
\item Zero becomes a number
\item Negative numbers treated as genuine numbers
\item The 19th Century
\begin{enumerate}
\item Irrationals: in the 19th century Dedekind, Cantor et al.  They
  find a precise definition of irrational numbers as ``cuts''; they
  become bona fide ``numbers''
\item Complex numbers: also in the 19th century, $\sqrt{-1}$ becomes a genuine number
\item Set theory: quantitative concept of number replaced by structural concept
\end{enumerate}
\item 20th Century
\begin{enumerate}
\item Category theory: alternative foundational theory replaces concept of set with concept of morphism; mathematics as essentially involving structural isomorphisms
\item Many other classes of mathematical objects and relations; number-qua-quantity (magnitude) discarded
\end{enumerate}
\end{enumerate}

\begin{remark}
  Operations?  Once we move to an algebraic perspective operations are
  as fundamental as objects.  The help define what it is to be an
  object of a certain type.
\end{remark}

\begin{remark}
  The ``variable'' problem.  Often used in a way that conflates word
  and world.  Reification of e.g. count of number of houses on a block
  as a variable suggests that it is a sort of property of a particular
  kind.  But this conflates what we invent (houses/block) and natural
  kinds as properties or entities in the world.  Houses per block is
  not a fact in the world, or, it is a contingent fact, something we
  invent (derive) from more fundamental facts such as house-ness and
  block-ness.
\end{remark}

\subsection{Quantity}

Quantity:  multitude (number) and magnitude

\begin{remark}
  The concept of quantity in measurement has two aspects, mathematical
  and empirical.  The mathematical notion of quantity has been
  superceded by structure.  The empirical notion of quantity is
  expressivist; when we use quantitative vocabulary to talk about the
  world, we project our mathematical concepts onto the world.  So both
  notions can be deflated; we can get along just fine without the
  concept of quantity.  On the mathematical side, it is supplanted by
  the concept of structure (structural position).  On the empirical
  side, it is otiose; we can discard it without compromising our
  ability to treat the world as mathematically structured.
\end{remark}

Counting as fundamental.  (Ordering also primitive?)

Counting reduces to the ability to put things in 1-to-1
correspondence.  It is therefore possible to count in practice without
having any number words or even concepts.  This is an essentially
pragmatic perspective on number; counting is something we know
\textit{how} to do, and number concepts are instituted by counting
practices.

\begin{remark}
  Counting: some writers confuse categorization and counting.
  E.g. ``According to Mann (2001), a discrete variable assumes values
  that are obtained from counting, for example, number of houses in a
  certain block while continuous variables are obtained by measuring
  and thus, assumes any value contained in an interval, for example,
  the height of a person. On the other hand, ordinal variables are
  obtained by ranking. Therefore, discrete and continuous variables
  are quantitative whereas ordinal variables are qualitative.''
  \cite[3-4]{yusoff_generation_2014} The problem here is mixing the
  concept of variable and the concept of scale.  (ordinal etc. apply
  to scales, not variables.)  Calling a discrete variable
  ``quantitative'' tells us nothing; it just says that counting is
  quantitative.  It doesn't say anything about the nature of counting
  or of the categorization that makes it possible.  In fact both
  so-called ``discrete variables'' and ``ordinal variables'' are
  qualitative insofar as the depend essentially on categorization.

  Continuity is a property of spaces (sets), not of quantities.
\end{remark}

\begin{remark}
  The quantity-quality dichotomy - false.  They're all (algebraic)
  structures.  The quality/quantity distinction is based on intuition,
  folk science - it does not reflect genuine dichotomy or difference
  in kind.  Temperature is a quality because we feel it (touch);
  length is not because we do not perceive length (we can ``grasp''
  the concept of length by either sight or touch).  But measurables
  are always conceptual, which makes them all basically
  ``qualitative'', insofar as the application of concepts is does not
  involve quantity.
\end{remark}

\begin{remark}
  TODO: find the article on the experiment showing that ants count
  their steps.  This is something they manage to do, even though they
  presumably have no awareness \textit{that} they are counting.
  Nonetheless \textit{we}, who do have such awareness, are justified
  in ascribing counting behavior to them.  In other words, it is
  entirely rational to say \textit{that} the ants count their steps.
\end{remark}

Number words as convenience devices: they allow us to say what we
could otherwise only do.  With ``three'' we can say \textit{that}
there are three apples in the basket; without such a word, we would
have to count (establish 1-1 correspondence).

One-to-one correspondence does not mean word-world correspondence nor
vice-versa.  It is an act of coordination, not representation.

\subsection{From Number to Structure}

\begin{remark}
The historical shift (mainly 19th c.) in mathematics from a focus on
quantity and magnitude to a focus on structure and function.

Significance to measurement: shift in perspective from measurement as
quantitative estimation to measurement as structural-functional modeling.
\end{remark}

\begin{remark}
  Compare role of group theory in physics.  Algebraic structures
  treated as models of aspects of nature.  This is not reducible to
  the traditional notion of measurement as the estimation of
  quantities, but it is no less essential to the science of physics.
  The lesson is that we should view quantitative estimation
  (measurement) as a species of the more general notion of structural
  (algebraic) modeling of nature.  After all, measurement scales are
  themselves algebraic structures (e.g. the real numbers are a field.)
\end{remark}

%%%%%%%%%%%%%%%%%%%%
\subsection{Mathematical Foundations}

\begin{remark}
  Why mathematical foundations?  Because they afford distinct
  \textit{conceptual} orientations.  If we adopt an inferential
  semantics, this means they have different implications.  The
  question is then what practical effect this may (or may not) have
  for the way we conceptualize measurment, especially in the human or
  behavioral sciences.
\end{remark}

\begin{itemize}
\item Set Theory
\item Category Theory
\item Type Theory
\end{itemize}

\subsubsection{Hierarchy}
The Fab 4 makes number basic, so that order depends on quantity.  But
this is wrong; both quantity and order are primitive.  Or at least
autonomous; you can have either without the other.  Or can you?  It
seems that quantity must always imply order, which would make order
primitive.  Can you have quantity without order?  Yes and no.  For
Euclid, quantity was inalienably associated with kind, so strictly
speaking it is not (for him) possible to order, say, a length of two
and an area of three.  But any two magnitudes of the same kind can be
ordered.

Quantity is a sufficient but not necessary condition for order.  The
elements of an order structure need not be quantitative in any sense
of the term.  We see this at the end of every year when ``Top Ten''
lists proliferate.

\begin{remark}
  Hierarchies: historical v. conceptual v. philosophical v...
\end{remark}

\subsection{From Quantitative Measurement to Algebraic Modeling}

\begin{remark}
  We can deflate the concept of quantity, just like we do with truth.
  To say some thing has a quantity of x just means that it corresponds
  to (is located at, is analogous to) a certain position in an algebraic
  structure.  Maybe this isn't deflation, but it is something.
\end{remark}

\begin{remark}
  Quantitative?  Monsieur, I have no need of that hypothesis.
\end{remark}

On this view, even e.g. temperature is not a quantity.  Or rather, we
have no need of the concept of quantity in order to measure
temperature.  Instead, temperature is construed as that aspect of the
world that has (or corresponds to) the structure of the Reals.  But in
modern mathematics, real numbers are not quantities.  They are cuts,
or locations, etc.  So this represents a fundamental conceptual shift.

\begin{remark}
  This perspective frees us from ontological entanglements.  Taking
  the real numbers as a \textit{model} of temperature helps us cope
  with temperatures in structural terms, but it says nothing about
  what temperature \textit{is}.  So we are not thereby committed to an
  ontology of temperatures as quantities, for example.
\end{remark}

%%%%%%%%%%%%%%%%%%%%
\section{The Ethnomethodological Perspective}

\begin{remark}
  EM studies of mathematics, counting, etc. provide a very different,
  practice-based (or pragmatist) perspective on measurement.
\end{remark}

%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Theories of Measurement}

\begin{itemize}
\item Operationalism
\item Classic
\item Representational
\item other...
\end{itemize}

\subsection{Operationalism}

The problem here is the rather obvious circularity.  An operational
definition of a ``construct'' contributes precisely nothing to the
fundamental question of whether the construct is ``real''.
Operationalism leads to vacuousness, as in ``general intelligence is
what gets measured by general intelligence tests''.

On the other hand, there is a sense in which all measurement is
operational.  In fact, that is pretty close to what pragmatism has to
say about it: no measurement without measurement practice.
Temperature measurement, for example, depends essentially on the
procedures we have devised for measuring temperature.  The problem is
that that is not all there is to it.  We need two more things: a
theory, and the test-revise-retest cycle.  So the problem with
Operationalism is that it is only part of the puzzle.



%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{The Fab Four}

\begin{abstract}
abstract
\end{abstract}

\begin{remark}
  The focus on ``scale'' is misplaced.  Transforms are central to this
  model, but mathematically they are derivative.  The primitive
  properties depend on which fundamental model of mathematics one
  prefers (set theory, category theory, etc.) but in any case
  transformations are constructed out of those raw materials (e.g. for
  set theory, membership, subset relation, ZFC axioms, etc.).
\end{remark}

\begin{remark}
  There are multiple ways to build a mathematical hierarchy.  We can
  distinguish primitive v. derived, but also basic v. extended
  (extensions add something but are not derived).  A pragmatic
  hierarchy would be based on which practices (and concepts)
  presuppose which.  Steven's hierarchy is different.
\end{remark}

Stevens' claim is that the four scales form a hierarchy, wherein each
scale subsumes those that precede it.  Thus the ratio scale
``contains'' the features of the nominal, ordinal, and interval
scales.  True enough, on Stevens' way of looking; but that is not the
only way of looking.  The argument here is a genealogical perspective
is better.

\subsection{Nominal Scales (Set Structure?)}

First problem: ``nominal'' is a misnomer.  Nominalism is a
philosophical doctrine which claims that ...  But when we categorize
things, we try to say something about things in the world.  It's not
just a matter of names.

Second problem: the sense-reference distinction.  Names always have
both; but for science it is critical that terms be treated as purely
extensional.  ``Electron'' is treated as a term whose extension
includes electrons and only electrons, full stop; any intensional
sense to the term is (in principle) irrelevant to scientific usage.
But it works, since we have a pretty good scientific idea of what
electrons are.

This works just fine for the hard sciences, but when it comes to the
human sciences it is a major problem.  What is the extension of, say,
``anxiety''?  The problem is that it is not even clear that it has an
extension.  So trying to measure anxiety seems kind of pointless.

Other examples: gender terms; legal status terms (e.g. undocumented,
legal permanent resident, etc.)  A term like ``male'' seems to have a
pretty clear intensional sense, but it is no small issue to decide on
its extension.  What about an individual with female sex chromosomes
who has male characteristics and functions as a male in society?

The problem goes beyond the trivial observation that terms may have
different meanings for different persons.  If that were the only issue
we could just settle on the correct meaning and classify people who
don't agree with it as in error.  But the problem is that there is no
way to settle on one true correct extensional meaning for any term.
Nor is there any reliable way to determine (a priori, as it were)
whether a particular use of a term is extensional or intensional.
Words inevitably have intensional senses.  A person might use ``The
Fab Four'' to refer to John, Paul, George, and Ringo without knowing
that they are the Beatles.  The classic example is the morning star
and the evening star: both refer to the same planet (same extension),
but we have no (a priori) way of knowing whether somebody who uses
either term is aware of that fact.  Terms themselves cannot help; they
cannot self-certify.

A strict formal account of such terms would have to resort to
intensional semantics, which is a relatively arcane area of modern
logic, involving so-called possible worlds and the like.  Not
something the average psychologist or sociologist is likely to have
mastered.

\begin{remark}
  First define algebraic structure (provisionally); then address the
  empirical issue of deciding on the right (conceptual) mapping; then
  show that the mapping reaches beyond language to connect with the
  world.
\end{remark}

\subsection{From Ratios to Intervals}

As a purely historical matter, the so-called ratio scale preceded the
interval scale (at least as those scales are conceived by Stevens).
The difference is not the presence or absence of ``true zero'', but
the very concept of \textit{zero}.  For the Greeks, number \textit{is}
quantity, and that is why they did not have a zero.  If number is
length, then absence of length cannot be a number.  The number line
has an origin, but that is a very different notion.  So the Greek
conception of number was essentially the ratio scale, without the
concept of zero \textit{as a number}.

\begin{remark}
  Comparison: same basis as \(\mathbb{n}\): comparison/analogy.

Two kinds of comparison: type identity (counting tokens), and
quality/intensity (ratio).  Also extensity as a kind of spatial
quality.

\end{remark}

\begin{remark}
  NB: the Kelvin scale has a zero, but it is not possible for anything
  to actually have a temperature of $0\deg$K.  So Kelvin's zero
  functions just like the origin of the Greek number line.
\end{remark}

By the same token, our use of ``zero'' to label a location on an
interval scale deceives us.  It would be more accurate to call it
``center''.

Furthermore, note that the Greek conception of a number as a
\textit{ratio} represents a radical expansion of the concept of
number.  Before that, we may imagine, number amounted to quantity.
There is a fundamental conceptual (and real?) difference between a
discrete quantum (thing), on the one hand, and the ratio on one
magnitude to another.

So in terms of Brandom's Question, one thing we must be able to do in
order to count as deploying ratios-as-numbers is to compare two
distinct individuals under one description.  For example, we must be
able to 1) treat two distinct rods as being ``the same'', as both
having extent in space, and 2) comparing one to the other (thus
ordering), and finally 3) treating one as a unit and the other as a
multiple of the unit.  All of this was possible even in the absence of
an explicitly articulated concept of ratios as numbers; the final
essentially creative move involved a change in \textit{discursive}
practice: the move to calling ratios numbers.  This change in practice
\textit{instituted} a change in concepts, rather than the other way
around.  Creatures incapable of practices involving \textit{treating}
distinct things as ``the same'' (in the appropriate way), comparing
them, treating one as a reference unit, etc. would not be capable of
coming up with the notion of ratio as number.

So historically the move to ratios-as-numbers involved changes in
practices and therefore concepts.

Historically, again, the Arabic/Indic invention of zero cannot be
viewed as merely adding a number to the Greek number line.  Rather, it
involved a fundamental change in the very concept of number.  Or more
accurately, it involved the emergence of a fundamentally different
concept of number, one that accomodated (what we call) rational
numbers without the concept of ratio-as-number.  The concept of
ratio-as-number is conspcuously absent in the earliest book on
algebra, al-Khawarizmi's \textit{Kitab al-Jabr wa-l-Muqabala} (from
which we have the word ``algebra'').  What the Greeks conceived of as
ratios, the Arabs conceived of as fractions, literally fracturing of a
single whole, rather than ratios of two wholes.  The task of algebra is to
restore wholes; hence the title of al-Khawarismi's manual: ``Concise
Book on al-Jabr (literally, bone-setting, mending of fractures) and
al-Muqabala (balance)'' (or: Dressing and Redressing).

\begin{remark}
  formally: algebras which ``come with'' transforms (morphisms).
  Shift of focus from elements (set theory) to morphisms (category
  theory).
\end{remark}

There is no way to conceive of zero as a quantity or magnitude, so to
characterize precisely the concept of number involved we must
characterize the practices involving number in which zero played a
role.  Here the fundamental innovation seems to involve algebraic
calculation, which requires (at least implicitly) negative numbers.

The detailed story of the practical and conceptual innovations
associated with the invention of algebra by Arabic-speaking cultural
actors is beyond the scope of this paper, but a few brief remarks are
in order.  Al-Khawarizmi's \textit{Kitab}, the earliest document
exhibiting genuinely algebraic manipulations, was a \textit{practical}
manual.  It contains no abstract mathematical theorizing; where it
refers to numbers, it always uses concrete numbers, i.e. numbers
\textit{of} things, and the problems it exhibits are mostly matters of
commercial or other financial accounting (e.g. dividing inheritances).
It does not suggest a notion of zero nor of negative numbers; but,
critically, it does involve addition and subtraction of quantities in
order to \textit{balance} accounts.

\begin{remark}
  Zero as pivot.  Algebraically, as a ``distinguished'' element having
  nothing to do with quantity, defined in terms of operations,
  e.g. the identity element of a group.
\end{remark}

To cut a long story short: the claim here is that the emergence of the
abstract mathematical concepts of zero and negative numbers \textit{as
  numbers} was historically and conceptually parasitic on practices
involving addition and subtraction, deficits and surpluses, and the
balancing of accounts.

On this view, zero emerges as the center of a structure, flanked on
either side by negative and positive numbers.  And again, when this
notion found its way into the European tradition it eventually
generated a fundamental change in the very concept of number - a
change that is historically and conceptually parasitic on practices of
calculation.

\begin{remark}
We have two sorts of genealogy: the historical record of the emergence
of practices and concepts, and the structural ``genealogy'' of the
practices that institute conceptual content.  By treating conceptual
structure as a genealogical structure I mean that we can identify the
structure of the concepts involved so as to show how the ``later''
structures build on the ``earlier'' ones.  This sort of ``genealogy''
is conceptual and logical (that is, philosophical) rather than
historical; what Huw Price calls ``philosophical anthropology''.  But
it still counts as a genealogy, in that it tells a story of how we
come to have the concepts we have.
\end{remark}

\begin{remark}
TODO: show more clearly (in Brandomian terms) how the
practical/conceptual structure of interval scales depends on the
practical/conceptual structure of ratio scales.  This would involve
showing how the features of the practices that institute the one
concept presuppose those that institute the other.  Or something like
that.
\end{remark}

Significance for the four scales?  For one thing, it reverses the
order of ratio and interval scales.  The ratio scale is more primitive
than the interval scale.  It also suggests a change in terminology.
The fundamental difference between ratio and interval scales is not
ratios v. intervals, but a change in number concept: a ratio scale has
an origin (misnamed ``true zero''), and an interval scale has a
center.  A ratio scale measures magnitudes; an interval scale measures
directed magnitudes (vectors).  So a better nomenclature would use
``scalar'' and ``vector'' for ``ratio'' and ``interval'',
respectively.

Alternatively, an interval scale is essentally an algebraic structure.
So we could call ratio scales arithmetic, and interval scales
algebraic.

\begin{remark}
  What about scales that use the complex numbers?  Why not?
\end{remark}

Relevance for measurement?  Hmmm.  At this point I'm not sure if any
substantial implications flow from this analysis.  But it is a
different interpretation of the scales so it could have pedogogical
implications.

One possibility: we take interval scales to be about structures with
centers (and hence measurements with orientations), rather than about
mere intervals.  This is a conceptual change.  If we suspect some
``construct'' has interval structure, this means something more than
merely that levels are expressed as intervals, or that only certain
operations on the scale are allowed.  It means that the structure
involved has a center, that individuals can have ``positive'' and
``negative'' levels of the measurand, and that the additive structure
of the scale implicates ``balancing'' and not merely accumulation.

\begin{remark}
``Additive'' structure is standardly taken to be an essential property
  of any empirically measurable attribute.  But the very term suggests
  the arithmetic scale, where addition means accumulation.  But the
  ``additivity'' of an algebraic scale with a center and ``negative
  measurements'' involves moving in both directions, so to speak; not
  merely accumulation and diminution, but also ``negation''.
  Arithmetic addition as a combining operation distinct from the
  corresponding algebraic operation.  The Greeks could not subtract 3
  from 2 (this qua characteristic of arithmetic additivity).  The
  Arabs, with an accounting-based, algebraic conception of
  computation, could, because the result could be conceptualized as a
  deficit rather than a length.
\end{remark}

Example: use of an interval scale of some sort with questions like
``Do you approve/disapprove of the job the President is doing?''  On
the mathematical interpretation of an interval scale as an algebraic
structure with a center, this forces us to treat disapproval as
negative approval.  That seems dubious; we could just as well treat
approval and disapproval as distinct qualities, each involving
an arithmetic ``ratio'' scale with an origin rather than a center.


%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Case Studies}

\subsection{Temperature}

What is temperature?  In the first instance, it is a subjective
\textit{sensation}, just like color or sweetness.  Perception of
temperature as such, like all perceptual awareness, is essentially
\textit{conceptual}.  To be aware \textit{that} an iron is hot is just
to be aware of the correctness of the application of the
(inferentially articulated) concept ``hot'' to the iron in question.
It is more than the merely sentient response to high temperature -
such as pulling away from the iron - that the hot iron might provoke
even in non-human creatures.

The measurement of temperature as it actually emerged historically
does not measure the sensation of warmth or coolness in this
conceptual sense; it measures neither the concept itself nor its use.
Nor it is a \textit{psychophysical} quantity that gets measured;
temperature measurements are not yoked to our pre-conceptual sensory
capacities.  Then what is it?  The answer to this question leads us to
considerations of theory, which were in fact central to the
development of temperature measurement.  But we can also offer a more
general response: measurable temperature is that aspect of ``objective
reality'' that stands in a causal relation to the ``language entry''
moves involving temperature vocabulary that are available to us; that
is, to those episodes of perceptual awareness leading to
non-inferential conceptual reports such as ``that iron is hot''.  In
this respect, what gets measured is not a conceptual matter, even
though our language-entry capacities are such that we can
\textit{apply} concepts like hot and cold to whatever it is that
temperature measurements measure.  Call it \textit{Temp-} (``temp
minus''), to indicate that it is the extra-linguistic correlate (or
cause) of the term ``temperature'' -- temperature without
``temperature''.


Now consider the original question of whether or not temperature is
measurable (has magnitude, is quantitative, etc.)  What are the
conditions of adequacy that must be met by a candidate explanation if
it to be considered genuinely explanatory?  How would we know that
temperature is measurable?  What would count as evidence?

The first thing to notice is that we cannot rely on the vocabulary of
measurement in answering this question, on pain of circularity.  We
cannot avail ourselves of scales, levels, degrees, etc. until we have
show that temperature is quantitatively measurable.

The fundamental hypothesis must be that it makes sense to talk of a
unit of temperature.  (Note that this already raises a problem: unit
of heat, maybe, but of temperature?)  But this is a hypothesis to be
defended, not an axiom to be used.

The significance of this is that even after we have constructed
thermometers, we are still left with the question of whether the units
of our (theoretical) temperature scale correspond to anything in the
real world.  The interval on our scale between 99 and 100 have the
same (linear) magnitude as the one between 0 and 1; it does not follow
that the corresponding temperature ``intervals'' have the same
``temperature magnitude''.  For how can we know ahead of time -
without using our measurement vocabulary - that the same ``amount'' of
temperature is involve in both cases?  The simple answer is: we cannot.

%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Pragmatism and Measurement}

In the case of the scales, we can take Brandom's Question as a schema
and ask four distinct questions:

What features must our measuring practices exhibit in order to count
as having the significance of:

\begin{itemize}
\item Categorization? (Nominal scale)
\item Ordering?  (Ordinal scale)
\item Measuring distance? (Interval scale)
\item Measuring ratio? (Ratio scale)
\end{itemize}

Stevens does not ask Brandom's Question; what matters for him is the
mathematical structure of the scales.  For example, interval scales do
not have a ``true'' zero, but ratio scales do; thus, Stevens sees
a ratio scale as an interval scale augmented by a true zero.

One problem with this mathematicized perspective is that it clashes
with history.

But it also has conceptual and logical problems.

We can ask ``Is Stevens' concept true (valid, etc.)?''  But that seems
the wrong question; it is a simple fact that we can describe the four
scales in just the way Stevens does.  By definition, interval scales
do not have a true zero and ratio scales do.  That's a purely
mathematical matter, and it is virtually always possible to offer
alternative descriptions of mathematical structures, no one of which
can be selected as the one true description.  But the point of the
four scales is to address issues of empirical measurement, so the
better question is whether the Stevens description is more
enlightening or useful than alternatives.  The argument here is that
it is not, that a pragmatic, genealogical description (Price:
philosophical anthropology) offers a better account of measurement.
Better in the sense that it focuses on our practices of measurement
rather than on the derived abstract description of the mathematical
properties of the scales we devise.

%%%%%%%%%%%%%%%%%%%%%%%%
\section{Causality and the Space of Reasons}

\begin{abstract}
abstract
\end{abstract}

\noindent
\cite{abell_narrative_2004} \\
\cite{crane_mental_1995} \\
\cite{gross_pragmatist_2009} \\
\cite{jackson_mental_1996} \\
\cite{lowe_causal_1993} \\
\cite{lowe_non-cartesian_2006} \\
\cite{macdonald_mental_1986} \\
\cite{menzies_causation_1993} \\
\cite{morris_causes_1986} \\
\cite{williamson_broadness_1998}

%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Measurement}

\begin{abstract}
abstract
\end{abstract}

\begin{remark}

Micro-macro:  temp as macro v. motion of molecules

Emergence: liquidity is an emergent property of H2O molecules; is temp
an emergent property of moving molecules?  It must be insofar as temp
is a subjective property (hot, cold, etc.)

Supervenience: or is temperature something that supervenes on groups
of molecules in motion?

\end{remark}

To measure is to characterize under a mathematical description.
Instead of ``measurement'', use the broader notion of mathematical
description.  So-called nominal measurement is not quantitative (nor
is ordinal measurement); calling it measurement clashes with our
intuition, which connects measurement with quantity or magnitude.  But
both do involve mathematical structure.  Mathematics is the science of
structure, not quantity.

Measurement claims are thus construed as claims about the structure of
some state of affairs in the world.  We express such claims in the
vocabulary of mathematics (plus an empirical vocabulary involving a
``dimension'' such as length); a ``valid'' measurement is a claim
expressing or describing a mathematical structure that corresponds
accurately (correctly) to the way things are.

Observable v. unobservable: implicit causal relationship.  Observable
as proxy for unobservable.  They must covary.

But this distinction is not simple.  Temperature \textit{sensation} is
observable, but sensation is distinct from the property in the world.
When we measure temperature, we use proxy properties, such as the
height of a column of mercury.  So temperature is not observable in
the required sense.  That is, its mathematical structure is not
directly observable.  Contrast with measurement of length, which is
directly observable.  Or is it?  To measure length we rely on the
sensations involved in vision: we see that the measurand is twice the
length of the unit instrument.  But not really: we do not \textit{see}
length per se; rather, we see a stick and use the term ``length'' to
express something about it, based on our experience with things in the
world, namely one of the ways we can compare them.  Which suggests
that terms like ``length'' are expressive in Brandom's sense: they
allow us to say what we can only otherwise do.  What we do is compare
things; saying that a stick is 1 meter long just saves us the trouble
of carrying out a comparison.

Alternatively we could express the same idea in terms of affordances:
when we look at a stick, we do not see its length, but we do see (so
to speak) one of its affordances: sticks afford lengthwise
comparison. (cf. Gibson)

Furthermore, there is the problem of the Myth of the Given and need to
explain how we go from merely responding to understanding.  This too
tends to subvert the observed/unobserved distinction, since we have to
ask just what it is that is observed, and what it is to observe.  We
cannot rely on mere sensory input, since that leads to the Myth.
Insofar as observation is a move in the Game of reasons, it is already
``theoretical'', that is, conceptual, from the very start.

IOW, the observable/unobservable distinction is often conflated with
the Given/theoretical distinction.  Observables are no more given than
unobservables are.  But they are directly connected to the causal
order.  So it would be better to talk of the distinction between
causal and rational orders instead of observables and unobservables.
Or perhaps we should stick to vocabulary talk, and make a distinction
between observation reports and other sorts of expressions.  Some
things afford observation reports, others do not.

Electrons are not observables; they do not afford observation reports.
But they are causally related to things that do afford such reports.
The job of theory is to articulate the hypothesized structure that
accounts for such reports in terms of causal relations with electrons.
This involves two of the three sorts of language moves: language
entries (things affording observation reports), and language-language
(theory).  Language exits involve what we do, not theoretical
predictions about what things in the world do, so the theory predicts
future language-entry moves (observations).

This is quite different from e.g. defining SES in terms of occupation,
etc.  Such definitions are conceptual and do not involve causal
relations.  Occupation does not cause SES; it is involved in what SES
\textit{means} (inferentially), rather than what it is or how it came to
be.  So defining it is not not about discovering the nature of
something in the world.  Contrast definition of electron: it must
answer to the way things are in the causal order.  Our notion of SES
must only answer to the way things are in the normative order, which
is our order, our way of doing things, the way we cope.  If it's
useful, we use it; if not, we try other definitions.  There is no
question of its truth or accurate representation of something in the
world.  Its a piece of methodological pragmatism: its only purpose is
to explain our doings.  No metaphysics here, and also no (genuine)
measurement.  Putative measurements of SES should be treated as
methodological conveniences, not as claims about the true state of
affairs in the world.  Claims that may help us cope or decide what to
do, or even predict what will happen.  Not because we've measured some
fact in the causal order, but because we know something about norms,
and norms have a kind of predictive power.  We know what ought to be
the case; whether things in fact will turn out that way is a different
matter.

SES measures as descriptions, which do not necessarily entail
predictions.  Compare studies primate sociality.

Evolution, selective pressures, etc.  Primate anthropologists want to
discover selection pressures, not ``causes'' or the ordinary type.
That is causality in evolution is different than causality in physics.
Evolutionary causality v. nomological causality.  SES measures as a
way of getting at ``selection pressures'' that result in social
change, etc.

``We can use the kinds of methods described here to test hypotheses
about the selective forces that shape behavioral strategies and to
construct comparisons across individuals, groups, or taxa.'' (Silk
et al. p. 223)

\subsection{Previous Work}

``Paraphrasing N.R. Campbell (Final Report, p.340), we may say that
measurement, in the broadest sense, is defined as the assignment of
numerals to objects and events according to rules.''
\parencite[677]{stevens_theory_1946}


``[M]eaningful measurement is possible only if enough is known about
the attribute so as to justify its logical operationalization into
prescriptions from which a measurement instrument can be developed.''
\parencite[787]{sijtsma_psychological_2012}

I would rather say the measurement is possible only if we have a
theory of description that allows us to make predictions involving
measurable (observable) phenomena.

\subsection{Model Theory}

Truth and consequences and measurement claims.

Relevance of MT: (valid) measurement is all about representation,
reference, truth, and validity.  (Although a pragmatist might argue it
is about what works rather than what corresponds to reality.)
Tarski's semantic theory of truth and model-theoretic account of
consequence together form the pinacle of this approach.

Tarski (Convention T and model theory) as the pinacle of
representational accounts of truth and consequences.

Relevance to measurement?  We want to know if our measurement claims
are truth, and if the inferences we make involving such claims are
valid.

Measurement claims reduce to mathematical claims plus empirical
claims.  The mathematical part of this accounts for structure.

Model theory: to prove a logical consequence relation between a set of
statements $\Gamma$ and a statement $A$, first translate them from the
formal calculus to the language of ordinary theory (e.g. Group
Theory), and then prove the resulting theorems using the informal
techniques of the ordinary theory.

Is something similar involved in ``proving'' an empirical measurement
claim (which is a theory)?  One difference is goals: the goal of MT is
to show that the formal calculus is ``good''.  Science isn't too
worried about formal calculi, but it would presumably be a good thing
if we could express scientific theories formally and thereby enable
formal (automated) reasoning about them.  But we don't normally
express measurement claims in a formal calculus.  Indeed, since
measurement claims necessarily involve an empirical component
(e.g. units of measure involving empirical properties, that is
properties of things in the world), to do so would require formalizing
such empirical notions, thus draining them of their empirical
content).

%%%%%%%%%%%%%%%%
\subsection{Measurement as assignment of numbers}

``Paraphrasing N.R. Campbell (Final Report, p.340), we may say that
measurement, in the broadest sense, is defined as the assignment of
numerals to objects and events according to rules.'' (Stevens, 1946,
p.677).

This can't be entirely correct.  What we assign is not a numeral but a
location or position in a mathematical structure.  E.g. to assign '3'
to a quantity is not to attach a free-standing ``numeral'' to it, but
to assign it a place in the structure of integers.

So each scale type corresponds to a class of mathematical structures.

Nominal:  sets?  But sets are partially ordered.

Ordinal:  sets?  But sets also give us intervals?

A nominal scale seems to involve set membership (characteristic
functions) at least.  But if we can measure the size (cardinality) of
a set we end up with order and intervals.  So it looks like we must
stipulate that these mathematical properties are not to be ascribed to
the measurands.  Thus nominal measurement involves a partial mapping
to sets, or rather a mapping to a set structure that does not admit of
ordering or intervals.  Hmmm.

Ordinal scales involve order without difference.  Again that makes it
hard to think of ordinal measurement as involving mapping to sets.
Lattice theory?

Does it make sense to think of a mapping to a logical rather than a
mathematical structure?

Better: we take set theory a little bit at a time.  Start with the
basic axioms, then define preorders, posets, etc.  So we can treat
something as a poset without introducing cardinal and ordinal numbers
(I think).

In any case, the upshot is that (representational) measurement
postulates a mathematical structure to the measurand.

Michell's concern with whether or not a variable or construct is in
fact quantitative can be restated in structural terms.  Quantitative
properties etc. (in the world) have mathematical structure.  Or, to
say that something is measurable is to say that it has a particular
kind of structure.

Validity ``how well the measured variable represents the attribute
being measured'' comes out as \textit{referential fidelity}.  Measurement
of something that lacks the requisite mathematical structure will then
lack referential fidelity.  Referential fidelity is broad enough to
cover both accuracy and precision of measurement.

\subsection{Validity as assessment of correctness}

I.e. to assess something as correct or incorrect is to measure it
against a norm.  In the case of e.g. temperature measurement, the norm
is the ``true'' temperature of the sample being measured.

Relevance: validity involves normativity and a kind of measurement
against (usually unstated) norms or ``true'' standards, which may be
(idealized) methods, etc.

Thus referential fidelity as correctness of representation.

\noindent References:

\noindent
\cite{chang_inventing_2004} \\
\cite{chang_measurement_2004} \\
\cite{chang_spirit_2004} \\
\cite{martin_counting_2009} \\
\cite{michell_normal_2000}\\
\cite{sherry_thermoscopes_2011}

See British Journal of Psychology, Aug 1997 vol 88 issue 3:
\cite{michell_quantitative_1997} and six commentaries.

%%%%%%%%%%%%%%%%
\subsection{Variables}

References:

\noindent
\cite{schwarz_is_2009}\\
\cite{toomela_variables_2008}\\
\cite{stam_fault_2010}

%%%%%%%%%%%%%%%%
\subsection{Error}

References:

\noindent
\cite{smith_refining_2011}

%%%%%%%%%%%%%%%%
\clearpage
\section{Validity, Reliability, Error}
\label{sub:Validity}

\begin{remark}
What is the point of worrying about validity?  Is it something in the
world that we are trying to discover?  Then we're trying to find ``the
right description of the world'' (Putnam).  Or is it a concept, so
that validity talk is about conceptual analysis and definition?

Or: we try to find the right description, and validity talk is part of
how we decide that we have found it.

\end{remark}

\begin{remark}
Why do psychometricians and the like worry so about validity?

Hypothesis: when they say ``validity'', what they're really interested
in is scientific legitimacy.  Effectively, to say that a test (etc.)
is valid is to say that it is in fact scientific.  Thats the practical
import of the concept of validity for them.

Unpack this.  Expose the assumptions and implications.
\end{remark}

key concepts:

\begin{itemize}
\item validity treated as a special kind of property - of what?
\item constructs
\item (latent) variables
\item indicators
\end{itemize}

``validity'' as code for:

\begin{itemize}
\item legitimacy
\item vindication
\item credibility
\item proof (good premises + valid inference)
\end{itemize}

\begin{remark}
  On the idea that validity something (a property, etc.) that we look
  for in scientific theories in order to distinguish good ones from
  bad: see Putnam on fact/value distinction.  We use value judgments -
  simplicity, parsimony, etc. - in every aspect of science (thought),
  esp. in weeding out bad theories.  For there is no external or
  objective criterion of acceptability for theories to which we can
  appeal, nor is there any such citerion that does not involve value
  judgments.
\end{remark}

\begin{remark}
  So along with the fact/value distinction, and the analytic/synthetic
  distinction, the internal/external distinction also collapses?  Or
  do we just exclude the notion of external?  No; we need to retain
  the idea of an external world that is independent of us and to which
  some of our judgments are answerable.  We don't get to just make
  stuff up and call it true (correct) for at least some of our claims.
  There is no external absolute authority that can decide for us which
  theories are true, or rather which we should endorse, but that does
  not mean there is no external world that is authoritative for some
  of our sayings.  But isn't that trying to have it both ways?  How
  can our theories answer to the world if we cannot appeal to the
  world or some other external authority to sort them out?  See
  Brandom.

Related issue: what counts as evidence?  How do we decide?  What are
we doing when we decide that something counts as strong (weak)
evidence in support of a theory?  What are the criteria of adequacy
for an account of evidence?
\end{remark}

\section{RCT and Self-validation}

See Cartwright on RCT as self-validating.  This seems to mean that
RCTs are valid by construction.

This nicely parallels industrial QA notions of guaranteeing quality by
designing a production process that prevents defects.

What's the logic here?  Is self-validation really possible?  How can a
process validate itself - isn't the very idea inherently circular?  Or
rather, don't we land in a regress?  After all, if the idea is to
specify a process that yields validity, how do we know that that
process is itself valid?

\section{Vocabularies}

Measurement as description.  Description v. evaluation.  Price on
naturalisms.  The bifurcation thesis.

\section{Conflation of Causal and Logical Relations}



\section{Deflationism about Validity}

\begin{remark}
  Deflationism seems to depend essentially on some form of
  expressivism.  Or maybe they amount to the same thing?
\end{remark}

How can we get out of this mess?  One way is to deflate the notion of
validity, just deny that it is a substantive property.  When we claim
that a result is valid etc. what we are really saying is that we
endorse it, approve of it, etc.  It's an expressive device.  Compare
the semantic deflationist's idea that calling something true amounts
to endorsing or approving of it.

So if we discard the notion of validity (since it does no real work),
don't we find ourselves lacking something essential?  Well, we just
need a vocabulary that allows us to say explicitly the sorts of things
we find it useful to be able to express with respect to a study or qx
technique.  For example: credibility, utility, legitimacy,
vindication, justification, etc.

\begin{remark}
  The notion of validity seems to be connected to the problem of
  deciding which theories we should endorse.  What are the criteria of
  adequacy for any notion (or theory) of validity?  Or: what are the
  requirements that should be met by any purported explanation of
  validity?  Both particular cases and the general idea.  Tarski gives
  us something like this for logical validity; what about ``validity''
  as the term is used by psychometricians, test theorists, etc.?

Contrast: claims of validity for a case, v. explanation of what
validity is.


\end{remark}

The objection will no doubt be that we need some kind of standard,
which is just to say that we want to measure this something (validity,
credibility, whatever).  Implicit in all this is the notion that there
is some ``objective'' fact of the matter to which our
study/technique/etc. is ansswerable. A study is valid iff - what?  If
it meets some definite ``objective'' criteria.  Methodological
criteria, conditions of validity, etc.  In the psychometrics and
testing tradition this appeal to external authority is expressed as
something along the lines of ``measures what it purports to measure''.
Which is only meaningful insofar as a) there is actually something
there to measure, and b) it is in fact susceptibel to measurement.

And usually this is expressed in statistical terms.  But that dog
won't hunt either - you cannot get to validity via statistics.  All
you can do is measure central tendencies and variance - not enough to
establish validity, which is a substantive notion. (analysis
elsewhere).

To say that sth is valid is just to say that it is admirable
(Peirce?), or perhaps that it is virtuous, that it has the virtues we
prize.

\section{Fact-Value}

Messick, for one, conflates two kinds of fact/value distinction.  The
Kantian idea that we structure our own experience (etc.), Sellars'
Myth of the Given, and etc. - such stuff shows how there is no data
that is ``objective'' and given i.e. ``data is theory-laden''.

So facts involve what Putnam calls ``epistemic values''.

Messick confuses epistemic and ethical values.  He seems to think that
although we cannot arrive at value-free facts, this is because brute
facts are always packaged with ethical values.  The idea seems to be
that ethical values are something separate from facts but always
attached to them somehow.  Whereas the real problem is that there is
no genuine distinction between fact and (epistemic) value.  Facts
express (as it were) our epistemic values.

Messick's confusion is clear in his distinction between the scientific
and social ``roles'' of validity - as if the social (value-laden)
aspect of (Messickian) validity is something distinct from the
science.  ``[I]t is fundamental that score validation is an empirical
evaluation of the meaning and consequences of measurement.  As such,
validation combines scientific inquiry with rational argument to
justify (or nullify) score interpretation and use.'' (p. 742) But
``scientific inquiry'' and ``rational argument'' are not two distinct
things that can be combined.  They are the same thing, at least
conceptually.  If there is a difference here, it is sociological -
science as a way of conduction oneself, etc.

Messickian validity boils down to some notion of empirical support for
theoretical explanations.  For him ``evidential basis'' seems to
correspond to ``real'' science, and ``consequential basis'' to
``rational argument''.

``[B]oth meaning and values are integral to the concept of
validity...'' (p. 747).  The problem here is that the contrast with
value is fact, not meaning.

``Meaning'' is not something that can be empirically ``validated''.

\section{Word-World}

One problem with e.g. Messick is fuzziness about the relation of
language to world.  Ditto for any notion of ``measuring a concept''.

Re: validity: is it supposed to be a property of things in the world,
or just a concept?  Per Messick, validity is ``associated with'' score
interpretation and use.  This would seem to imply that it is a matter
of language (concepts).  But the language is just sloppy; ``score
interpretation'' might (should) refer to how we take a score to relate
to some fact in the world, in which case the question is just what is
validity-in-the-world.

In any case, Messick's whole discussion is muddled on this point; it
is rarely clear when he is talking about facts, concepts, or the
relation between the two.  Is a ``construct'' supposed to be something
in the world or a concept the describes some aspect of the world?

Construct v. ``indicators''.

Compare positivist notions of observational language v. theoretical
language.  So-called indicators are (I understand) supposed to be
empirical observables.  Their relation to the construct is (must be) a
matter of theory; but then is that theoretical (conceptual) structure
to be taken as a mirror of reality, such that the construct is a real
(albeit ``hidden'') bit of the world and its relations to the
indicators are real relations in the world?

\section{Hypothetical Entities}

Putnam, Brandom, etc. - if the existence of (some) hypotheticals makes
no difference in the way things are then we can just discard them.  As
Putnam puts it, ``Would mathematics \textit{work} one bit less well if
these funny objects \textit{stopped} existing?  Those who posit
``abstract entities'' to account for the success of mathematics do not
claim that we (or any other things in the empirical world)
\textit{interact} with the abstract entities.  But if any entities do
not interact with us or with the empirical world \textit{at all}, then
doesn't it follow that \textit{everything wouuld be the same if they
  didn't exist}?'' (Collapse, p. 33)

This points out another problem with e.g. latent variables, namely
that they are supposed to have causal powers, but, insofar as they are
abstract at least, they have no connection to the empirical world and
so cannot cause anything.  The counterargument would presumably be
that hidden does not necessarily mean abstract.  But in that case they
must have a location in space-time, even if we don't know what it is.
But this just leads to more problems: where are hidden psychological
processes supposed to occur?  It can't be the brain, since they are
(by stipulation) psychological, not neurological.

So it seems we have no choice but to treat postulation of hidden stuff
as a matter of Brandomian methodological pragmatism: useful, but
without ontological consequences.  ``Constructs'' may be useful for
explaining observable indicators, but they don't really exist in any
meaningful sense.  But the usual story goes the other way around:
indicators are useful because they are how we get constructs.

Another perspective: hard science starts with observation and moves to
number, theory, etc.  Psychometrics reverses this, starting with
number and theory (latent vars, etc.) and then seeking observational
support.

Example: temperature v. anxiety.  The former is directly associated
with publicly available bodily experience.  Is the latter?  Anxiety
may be experienced by individuals but it is not public in the way the
temperature of an external phenomenon is public.  The sensation of
temperature may be private, but it is directly linked to the (public)
causal order.  So although both are essentially conceptual, only the
former answers to the state of the world.  There is no prima facie
reason to think that the concept of anxiety represents something in
the world; in this respect it is just like ``Zeus'' or ``phlogiston''.
So trying to measure ``it'' inescapably involves starting with a
speculative ontological hypothesis.  Whereas trying to measure
temperature starts with something observable.

Same point made from perspective of anthropology: we can be 100\%
confident that all cultures encounter things in the world that are hot
or cold, regardless of their concepts.  But we cannot be sure that
anxiety - either the thing itself or the concept/term - is a cultural
universal.

\begin{remark}
  TODO: explicit comparison of psychometrics with failed but arguably
  scientific measurement projects like the caloric theory, phlogiston,
  etc. on the one hand, and clearly pseudoscientific projects like
  astrology, ESP, etc. on the other.  The task is to determine which
  one psychometrics is.  Is psychometrics in a ``caloric theory''
  phase, genuinely scientific yet lacking good theories, or is it like
  astrology?  It's open to the psychometrician to argue that the
  science is young, and that just because it is a science it will
  self-correct, so that eventually we will have the theories and
  practices needed to make precise measurements of anxiety (or its
  successor concept) - possibly by measuring brain states and
  structures.  The problem with this argument is that it continues to
  overlook or ignore the fact that categories like ``anxiety'' are
  only intelligible in the space of reasons; they are creatures of the
  normative order, not of the natural (causal) order.  So the question
  becomes whether they answer to anything in the causal order in the
  way that temperature answers to physical states of the world.  The
  fundamental hypothesis (or speculation) of psychometrics seems to be
  that the concepts of the folk psychology from which psychometrics
  draws its ``constructs'' are causally related in some way to the
  causal order.  The objection is that there is no such causal
  relation, that the relations between these concepts is entirely
  normative.
\end{remark}

\section{Personal v. Subpersonal}

Reasons v. causes

\section{Spaces}

\subsection{Natural space of causes}

\subsection{Discursive space of reasons}

\clearpage

\section{Mensuration without Representation}
\begin{remark}

Measurement as a species of modeling.

Quantities, ``levels'', etc. - too narrow.  E.g. gravity as a force,
force as a quantity; but Einstein taught us that gravity is not in
fact a force.  Or: caloric, heat as a fluid, which has quantity.  But
heat is not a fluid. Moral: quantification is based on analogy.


Micro-macro:  temp as macro v. motion of molecules

Emergence: liquidity is an emergent property of H2O molecules; is temp
an emergent property of moving molecules?  It must be insofar as temp
is a subjective property (hot, cold, etc.)

Supervenience: or is temperature something that supervenes on groups
of molecules in motion?

\end{remark}

To measure is to characterize under a mathematical description.
Instead of ``measurement'', use the broader notion of mathematical
description.  So-called nominal measurement is not quantitative (nor
is ordinal measurement); calling it measurement clashes with our
intuition, which connects measurement with quantity or magnitude.  But
both do involve mathematical structure.  Mathematics is the science of
structure, not quantity.

Measurement claims are thus construed as claims about the structure of
some state of affairs in the world.  We express such claims in the
vocabulary of mathematics (plus an empirical vocabulary involving a
``dimension'' such as length); a ``valid'' measurement is a claim
expressing or describing a mathematical structure that corresponds
accurately (correctly) to the way things are.

Observable v. unobservable: implicit causal relationship.  Observable
as proxy for unobservable.  They must covary.

But this distinction is not simple.  Temperature \it{sensation} is
observable, but sensation is distinct from the property in the world.
When we measure temperature, we use proxy properties, such as the
height of a column of mercury.  So temperature is not observable in
the required sense.  That is, its mathematical structure is not
directly observable.  Contrast with measurement of length, which is
directly observable.  Or is it?  To measure length we rely on the
sensations involved in vision: we see that the measurand is twice the
length of the unit instrument.  But not really: we do not \it{see}
length per se; rather, we see a stick and use the term ``length'' to
express something about it, based on our experience with things in the
world, namely one of the ways we can compare them.  Which suggests
that terms like ``length'' are expressive in Brandom's sense: they
allow us to say what we can only otherwise do.  What we do is compare
things; saying that a stick is 1 meter long just saves us the trouble
of carrying out a comparison.

Alternatively we could express the same idea in terms of affordances:
when we look at a stick, we do not see its length, but we do see (so
to speak) one of its affordances: sticks afford lengthwise
comparison. (cf. Gibson)

Furthermore, there is the problem of the Myth of the Given and need to
explain how we go from merely responding to understanding.  This too
tends to subvert the observed/unobserved distinction, since we have to
ask just what it is that is observed, and what it is to observe.  We
cannot rely on mere sensory input, since that leads to the Myth.
Insofar as observation is a move in the Game of reasons, it is already
``theoretical'', that is, conceptual, from the very start.

IOW, the observable/unobservable distinction is often conflated with
the Given/theoretical distinction.  Observables are no more given than
unobservables are.  But they are directly connected to the causal
order.  So it would be better to talk of the distinction between
causal and rational orders instead of observables and unobservables.
Or perhaps we should stick to vocabulary talk, and make a distinction
between observation reports and other sorts of expressions.  Some
things afford observation reports, others do not.

Electrons are not observables; they do not afford observation reports.
But they are causally related to things that do afford such reports.
The job of theory is to articulate the hypothesized structure that
accounts for such reports in terms of causal relations with electrons.
This involves two of the three sorts of language moves: language
entries (things affording observation reports), and language-language
(theory).  Language exits involve what we do, not theoretical
predictions about what things in the world do, so the theory predicts
future language-entry moves (observations).

This is quite different from e.g. defining SES in terms of occupation,
etc.  Such definitions are conceptual and do not involve causal
relations.  Occupation does not cause SES; it is involved in what SES
\it{means} (inferentially), rather than what it is or how it came to
be.  So defining it is not not about discovering the nature of
something in the world.  Contrast definition of electron: it must
answer to the way things are in the causal order.  Our notion of SES
must only answer to the way things are in the normative order, which
is our order, our way of doing things, the way we cope.  If it's
useful, we use it; if not, we try other definitions.  There is no
question of its truth or accurate representation of something in the
world.  Its a piece of methodological pragmatism: its only purpose is
to explain our doings.  No metaphysics here, and also no (genuine)
measurement.  Putative measurements of SES should be treated as
methodological conveniences, not as claims about the true state of
affairs in the world.  Claims that may help us cope or decide what to
do, or even predict what will happen.  Not because we've measured some
fact in the causal order, but because we know something about norms,
and norms have a kind of predictive power.  We know what ought to be
the case; whether things in fact will turn out that way is a different
matter.

SES measures as descriptions, which do not necessarily entail
predictions.  Compare studies primate sociality.

Evolution, selective pressures, etc.  Primate anthropologists want to
discover selection pressures, not ``causes'' or the ordinary type.
That is causality in evolution is different than causality in physics.
Evolutionary causality v. nomological causality.  SES measures as a
way of getting at ``selection pressures'' that result in social
change, etc.

``We can use the kinds of methods described here to test hypotheses
about the selective forces that shape behavioral strategies and to
construct comparisons across individuals, groups, or taxa.'' (Silk
et al. p. 223)

\subsection{Previous Work}

``Paraphrasing N.R. Campbell (Final Report, p.340), we may say that
measurement, in the broadest sense, is defined as the assignment of
numerals to objects and events according to rules.''
\parencite[677]{stevens_theory_1946}


``[M]eaningful measurement is possible only if enough is known about
the attribute so as to justify its logical operationalization into
prescriptions from which a measurement instrument can be developed.''
\parencite[787]{sijtsma_psychological_2012}

I would rather say the measurement is possible only if we have a
theory of description that allows us to make predictions involving
measurable (observable) phenomena.

\subsection{Model Theory}

Truth and consequences and measurement claims.

Relevance of MT: (valid) measurement is all about representation,
reference, truth, and validity.  (Although a pragmatist might argue it
is about what works rather than what corresponds to reality.)
Tarski's semantic theory of truth and model-theoretic account of
consequence together form the pinacle of this approach.

Tarski (Convention T and model theory) as the pinacle of
representational accounts of truth and consequences.

Relevance to measurement?  We want to know if our measurement claims
are truth, and if the inferences we make involving such claims are
valid.

Measurement claims reduce to mathematical claims plus empirical
claims.  The mathematical part of this accounts for structure.

Model theory: to prove a logical consequence relation between a set of
statements $\Gamma$ and a statement $A$, first translate them from the
formal calculus to the language of ordinary theory (e.g. Group
Theory), and then prove the resulting theorems using the informal
techniques of the ordinary theory.

Is something similar involved in ``proving'' an empirical measurement
claim (which is a theory)?  One difference is goals: the goal of MT is
to show that the formal calculus is ``good''.  Science isn't too
worried about formal calculi, but it would presumably be a good thing
if we could express scientific theories formally and thereby enable
formal (automated) reasoning about them.  But we don't normally
express measurement claims in a formal calculus.  Indeed, since
measurement claims necessarily involve an empirical component
(e.g. units of measure involving empirical properties, that is
properties of things in the world), to do so would require formalizing
such empirical notions, thus draining them of their empirical
content).

%%%%%%%%%%%%%%%%
\subsection{Measurement as assignment of numbers}

``Paraphrasing N.R. Campbell (Final Report, p.340), we may say that
measurement, in the broadest sense, is defined as the assignment of
numerals to objects and events according to rules.'' (Stevens, 1946,
p.677).

This can't be entirely correct.  What we assign is not a numeral but a
location or position in a mathematical structure.  E.g. to assign '3'
to a quantity is not to attach a free-standing ``numeral'' to it, but
to assign it a place in the structure of integers.

So each scale type corresponds to a class of mathematical structures.

Nominal:  sets?  But sets are partially ordered.

Ordinal:  sets?  But sets also give us intervals?

A nominal scale seems to involve set membership (characteristic
functions) at least.  But if we can measure the size (cardinality) of
a set we end up with order and intervals.  So it looks like we must
stipulate that these mathematical properties are not to be ascribed to
the measurands.  Thus nominal measurement involves a partial mapping
to sets, or rather a mapping to a set structure that does not admit of
ordering or intervals.  Hmmm.

Ordinal scales involve order without difference.  Again that makes it
hard to think of ordinal measurement as involving mapping to sets.
Lattice theory?

Does it make sense to think of a mapping to a logical rather than a
mathematical structure?

Better: we take set theory a little bit at a time.  Start with the
basic axioms, then define preorders, posets, etc.  So we can treat
something as a poset without introducing cardinal and ordinal numbers
(I think).

In any case, the upshot is that (representational) measurement
postulates a mathematical structure to the measurand.

Michell's concern with whether or not a variable or construct is in
fact quantitative can be restated in structural terms.  Quantitative
properties etc. (in the world) have mathematical structure.  Or, to
say that something is measurable is to say that it has a particular
kind of structure.

Validity ``how well the measured variable represents the attribute
being measured'' comes out as \it{referential fidelity}.  Measurement
of something that lacks the requisite mathematical structure will then
lack referential fidelity.  Referential fidelity is broad enough to
cover both accuracy and precision of measurement.

\subsection{Validity as assessment of correctness}

I.e. to assess something as correct or incorrect is to measure it
against a norm.  In the case of e.g. temperature measurement, the norm
is the ``true'' temperature of the sample being measured.

Relevance: validity involves normativity and a kind of measurement
against (usually unstated) norms or ``true'' standards, which may be
(idealized) methods, etc.

Thus referential fidelity as correctness of representation.

\noindent References:

\noindent
\cite{chang_inventing_2004} \\
\cite{chang_measurement_2004} \\
\cite{chang_spirit_2004} \\
\cite{martin_counting_2009} \\
\cite{michell_normal_2000}\\
\cite{sherry_thermoscopes_2011}

See British Journal of Psychology, Aug 1997 vol 88 issue 3:
\cite{michell_quantitative_1997} and six commentaries.

%%%%%%%%%%%%%%%%
\subsection{Variables}

References:

\noindent
\cite{schwarz_is_2009}\\
\cite{toomela_variables_2008}\\
\cite{stam_fault_2010}

%%%%%%%%%%%%%%%%
\subsection{Error}

References:

\noindent
\cite{smith_refining_2011}

\section{Notes}

If we reject the quantitative-qualitative dichotomy (while retaining
the distinction) in favor of algebraic modeling, how do we then handle
qualitative stuff?  This becomes: what do we do with that (empirical)
vocab, since we no longer have a demarcation between quantitative and
qualitative?  This dichotomy seems to correspond with Price's
bifurcation stuff and the placement game.  Quantitative entities can
be placed on the mathematical map (world) while qualitative ones
cannot.  This turns Price's game around: instead of trying to match
terms to facts, we try to match facts to mathematical structures or
entities (or vice-versa?).

\subsection{Monism v. Pluralism}

Is (empirical) measurement one thing?  Certainly there are multiple
ways to measure stuff (e.g. different techniques for measuring
temperature), so methodological pluralism is no great discovery.  What
do they all have in common?  Presupposition of mathematical structure
of measurand?  Anything else?  Is there anything we would count as
measurement that does not have this character?

And what about ontological pluralism?  Measurands - are they all the
same in some respect that renders them measurable?

Obviously categorization and ordering are distinct from counting and
estimating magnitude.

\subsection{Logic}

Compare representational measurement with logical modeling.  We assign
bits of the world to logical vars, etc. and prove theorems.  Provable
theorems correspond to facts in the world, just like measured
properties.  We normally apply or project a logical structure on the
world, just as measurement projects a mathematical structure.

But this does not commit us to a metaphysics.  It is rather a matter
of our practices.  Take for example Brandom's account of the
conditional as a device that makes it possible to say what we could
otherwise only do, namely endorse material inferences.  To assert ``if
A then B'' is not to describe the world; it does not entail an
ontological or metaphysical commitment to the existence of this
logical relation (material implication) in the world (e.g. as an
immanent property or the like).  Instead it just makes explicit the
inference that is implicit in our practical endorsement of the
inference from A to B.  We can \textit{treat} that inferential move as
good even if our language lacks an ``if ... then ...'' device.  When
we add such a device, it allows us to \textit{say that} it is a good
inference.

Is the same sort of structure characteristic of measurement vocab?
Does it allow us to say what we could otherwise only do (by adopting
the appropriate deontic attitudes, etc.)?  To examine this we can
follow Brandom's strategy and try to imagine a language that had no
measurement vocab and see what happens.  How does measurement vocab
``say that'', what is made explicit, and what are its implicit forms?

Minimal example: ``the rod is 2 meters long''.  This asserts a claim
that explicitly mentions the length measurement.  If we did not have
language like ``2 meters long'', then how could we implicitly endorse
anything like the explicit claim?  By treating something as twice the
length of some other ``meter'' thing?  Or, perhaps, by using it to do
some job that only a 2 meter long rod can do?  I.e. using it
\textit{as} a 2-meter long rod.  After all that is how money works - a
dollar bill is worth a dollar only because we treat it that way.  So
maybe currency is actually the paradigm case of measurement.  ``The
price of oil is \$100 per barrel'' says explicitly what we could
otherwise only do - treat a barrel of oil as having a certain value.
The language of numbers and dollars just makes that explicit.

Note: on this view, no representation.  ``\$100 per barrel'' does not
represent anything; instead it makes something explicit, and that
something is practical, involves doings, also coordination.  Or it
enables coordination, which is the function of language.  It makes
explicit practical attitudes, which are the stuff of coordinated
action.  [NB: Elaborate on this]

So measurement vocab tied to proposition formation and contentfulness
- saying \textit{that}.

(And the point of all this is to ``ground'' meaning in practice, to
justify the anti-representational stance, etc.)

(Maybe we should first examine mathematical vocab and ask what it
makes explicit, separate from measurement if possible.  Implicitly
treating something as quantitative would involve treating it as
additive, for example.)

Even simpler example: ``the iron is hot''.  Here we do not have the
vocab of quantity.  What does ``hot'' make explicit?  \textit{That}
the iron is so?  Without it all we could do is respond differentially
to the iron - sense (tactilely) that it is hot and yelp and pull away
from it.  This suggests that language in general is expressive in this
sense - that such making explicit is the (a?) fundamental role of
language.  Which suggests that the way to explain language is to
explain this implicit-explicit relation.



\subsection{Mathematical v. Scientific Measurement}

Mathematical \textit{Measure} Theory (MMT) v. Scientific
\textit{Measurement} Theory (SMT).  The former makes precise our
informal notions of magnitude measurement; the latter addresses the
link between theory and the world.  SMT is inevitably involves
semantics and pragmatics.  (NB distinction between what counts
(conceptually) as empirical measurement (what it is) and what works
effectively or efficiently (methods of measurement).

Theories of measurement (at least some of them) include some account
of measurement processes or the like.  TODO: clarify relation of
conceptual structure of measurement and practices of measurement.
Operationalism might say they are the same thing.  

\clearpage
\appendix
\begin{appendices}
\section{Bibliography}
%% \addcontentsline{toc}{chapter}{Bibliography}
%% \bibliographystyle{plainnat}
\printbibliography[heading=none]
\end{appendices}

\end{document}
